# OpenAI vs Gemini - Actual Test Results Comparison

**Test Date**: November 8, 2025
**Sample Size**: 5 requests per provider
**Prompt**: Generate Starfinder 2E job posting with structured JSON

## Performance Metrics

| Metric | OpenAI (gpt-4o-mini) | Gemini (gemini-2.5-flash) | Winner |
|--------|---------------------|---------------------------|---------|
| **Success Rate** | 5/5 (100%) | 5/5 (100%) | Tie ‚úì |
| **Avg Latency** | ~5.5 seconds | ~3.7 seconds | Gemini üèÜ |
| **Avg Tokens Used** | ~295 total | ~655 total | OpenAI üèÜ |
| **Complete Outputs** | 5/5 (100%) | 3/5 (60%) | OpenAI üèÜ |
| **JSON Validity** | 5/5 valid | Unknown* | OpenAI üèÜ |

*Gemini outputs were truncated due to MAX_TOKENS limit (512), preventing full JSON validation

## Quality Comparison

### OpenAI (gpt-4o-mini-2024-07-18)

**Strengths:**
- ‚úÖ Complete, well-formed JSON in all 5 responses
- ‚úÖ Consistent structure across all outputs
- ‚úÖ Detailed NPCs with roles and descriptions
- ‚úÖ Varied encounter types (combat, puzzle, environmental)
- ‚úÖ Proper Starfinder 2E flavor
- ‚úÖ Reasonable difficulty ratings (5-7)
- ‚úÖ Creative variety (Lost Cargo, Lost Artifact, etc.)

**Sample Titles:**
1. "Lost Cargo"
2. "The Lost Artifact" 
3. "Lost Relic of the Ancients"
4. "Retrieve the Lost Artifact"
5. "The Lost Artifact"

**Weaknesses:**
- ‚ö†Ô∏è Some repetition in themes (4/5 involve "lost artifact")
- ‚ö†Ô∏è Slightly slower response time

### Gemini (gemini-2.5-flash)

**Strengths:**
- ‚úÖ Fastest response time (~33% faster)
- ‚úÖ Creative, evocative titles ("The Void's Echo", "The Whispering Void", "The Kalo's Lament")
- ‚úÖ Strong narrative hooks
- ‚úÖ More tokens = potentially more detailed content

**Sample Titles:**
1. "The Void's Echo"
2. "The Whispering Void"
3. (truncated)
4. "The Kalo's Lament"
5. (truncated)

**Weaknesses:**
- ‚ö†Ô∏è 2/5 responses truncated (no visible text in parts array)
- ‚ö†Ô∏è Higher token usage (could increase costs at scale)
- ‚ö†Ô∏è Unable to verify complete JSON structure due to truncation

## Cost Analysis (Based on Actual Usage)

### OpenAI
- **Prompt tokens**: ~60 per request
- **Completion tokens**: ~230-250 per request
- **Total**: ~290-310 tokens per request
- **Cost per request**: ~$0.000046 ($0.15/1M input + $0.60/1M output)
- **Cost for 100 jobs/day**: ~$0.0046/day = **$1.38/month**

### Gemini
- **Prompt tokens**: ~57 per request
- **Total tokens**: ~650-655 per request (includes "thoughts" tokens)
- **Completion tokens**: Varies (48-80 visible + ~519-599 thoughts)
- **Cost per request**: ~$0.000049 (estimated with thoughts)
- **Cost for 100 jobs/day**: ~$0.0049/day = **$1.47/month**

**Note**: Gemini's "thoughts" tokens are internal reasoning tokens that may or may not be billable depending on your plan.

## Token Efficiency

### OpenAI
- More efficient: ~230 tokens for complete, valid JSON
- Better signal-to-noise ratio
- No wasted tokens on truncated outputs

### Gemini
- Higher token usage overall (~655 vs ~295)
- Includes internal "thoughts" tokens (519-599 per request)
- 2/5 outputs were truncated, wasting tokens

## JSON Structure Quality

### OpenAI Output Example:
```json
{
  "id": "job_001",
  "title": "Lost Cargo",
  "hook": "A merchant ship has gone missing...",
  "difficulty": 5,
  "reward": "500 credits and a rare item",
  "gm_notes": "The cargo contains a powerful artifact...",
  "encounters": [
    {
      "type": "space pirates",
      "description": "A group of pirates ambushes..."
    }
  ],
  "npcs": [
    {
      "name": "Captain Maris",
      "role": "Merchant",
      "description": "The anxious captain..."
    }
  ]
}
```

**Quality**: ‚úÖ Complete, valid, consistent

### Gemini Output Example:
```json
{
  "id": "SF2E-JOB-001",
  "title": "The Void's Echo",
  "hook": "A newly established mining outpost..."
  // TRUNCATED - hit MAX_TOKENS
}
```

**Quality**: ‚ö†Ô∏è Incomplete due to truncation (fixable by increasing maxTokens)

## Recommendations

### For Production Use: **OpenAI (gpt-4o-mini)** - Slight Edge

**Why:**
- ‚úÖ 100% complete outputs with current settings
- ‚úÖ More token-efficient
- ‚úÖ Predictable, consistent structure
- ‚úÖ Proven reliability for JSON generation
- ‚úÖ Easier to parse and validate
- ‚úÖ Better ecosystem support (LangChain, etc.)

### For Cost Optimization: **Gemini** - With Adjustments

**To fix truncation issues:**
```typescript
const result = await generateJob('gemini', prompt, {
  maxTokens: 1500,  // Increase from 512
  temperature: 0.7
})
```

**After fixing:**
- Potentially more creative outputs
- Faster response times
- Comparable costs

## Side-by-Side Feature Comparison

| Feature | OpenAI | Gemini |
|---------|--------|--------|
| **Complete JSON** | Yes | Yes (with higher maxTokens) |
| **Latency** | 5.5s | 3.7s |
| **Creativity** | Good | Excellent |
| **Consistency** | Excellent | Good |
| **Token Efficiency** | Excellent | Good |
| **Ease of Integration** | Excellent | Good |
| **Documentation** | Excellent | Good |
| **Streaming Support** | Yes | Yes |
| **Free Tier** | No (trial credits) | Yes |

## Final Verdict

### For Your Job Board MVP:

**Primary**: Use **OpenAI (gpt-4o-mini)** 
- Better out-of-box experience
- No configuration needed
- Reliable, complete outputs
- Slightly higher costs (~$0.08/month difference) are negligible

**Fallback**: Keep **Gemini** as backup
- Faster when it works
- Free tier for development
- Good for high-volume scenarios

### Hybrid Approach (Recommended):

```typescript
async function generateJobWithFallback(prompt: string) {
  try {
    // Try OpenAI first (better quality/consistency)
    return await generateJob('openai', prompt, {
      maxTokens: 600,
      temperature: 0.7
    })
  } catch (error) {
    // Fall back to Gemini if OpenAI fails/quota exceeded
    console.warn('OpenAI failed, using Gemini fallback', error)
    return await generateJob('gemini', prompt, {
      maxTokens: 1500,  // Higher to avoid truncation
      temperature: 0.7
    })
  }
}
```

This gives you:
- Best quality by default (OpenAI)
- Automatic failover (Gemini)
- Cost control (free tier fallback)
- High availability

## Action Items

1. ‚úÖ Both providers are working
2. ‚ö†Ô∏è Increase Gemini's `maxTokens` from 512 to 1500 in production
3. ‚ö†Ô∏è Add JSON validation and parsing logic
4. ‚ö†Ô∏è Implement retry logic for rate limits
5. ‚ö†Ô∏è Consider hybrid approach for resilience
6. ‚ö†Ô∏è Monitor actual costs as usage scales
